[cite_start]이 논문은 페이스북이 세계 최대 소셜 네트워크를 지원하기 위해 memcached를 분산 키-값 스토어로 구축하고 확장한 방법을 설명합니다[cite: 6].

**핵심 포인트:**

* **배경 및 동기**:
    * [cite_start]인기 있는 소셜 네트워킹 사이트는 컴퓨팅, 네트워크 및 I/O 측면에서 상당한 인프라 문제를 야기합니다[cite: 9, 10].
    * [cite_start]페이스북의 시스템은 초당 수십억 건의 요청을 처리하고 수조 개의 항목을 저장하여 전 세계 10억 명 이상의 사용자에게 풍부한 경험을 제공합니다[cite: 7].
    * [cite_start]memcached는 간단하고 잘 알려진 인메모리 캐싱 솔루션입니다[cite: 5]. [cite_start]페이스북은 오픈 소스 memcached를 개선하여 분산 키-값 스토어를 구축했습니다[cite: 12].
    * [cite_start]워크로드가 읽기 작업에 의해 지배되므로 캐싱이 상당한 이점을 제공합니다[cite: 30, 31].
    * [cite_start]memcached는 저렴한 비용으로 공유 스토리지 풀에 대한 낮은 지연 시간 액세스를 제공하는 인메모리 해시 테이블의 오픈 소스 구현입니다[cite: 16].

* **설계 원칙 및 목표**:
    * [cite_start]캐시 계층과 영속성 계층을 분리하여 워크로드 변화에 따라 각 계층을 독립적으로 조정할 수 있습니다[cite: 68].
    * [cite_start]모든 변경 사항은 사용자 또는 운영 문제에 영향을 미쳐야 합니다[cite: 90].
    * [cite_start]일시적으로 오래된 데이터를 읽을 가능성은 응답성과 유사하게 조정할 수 있는 매개변수로 취급됩니다[cite: 91]. [cite_start]과도한 부하로부터 백엔드 스토리지 서비스를 보호하기 위해 약간 오래된 데이터를 노출하는 것을 허용합니다[cite: 92].
    * [cite_start]단순성은 매우 중요합니다[cite: 599].

* **단일 클러스터 내의 확장 (지연 시간 및 부하 감소)**:
    * [cite_start]**클라이언트 측 최적화**: 지연 시간을 줄이기 위해 memcache 클라이언트(각 웹 서버에서 실행)에 중점을 둡니다[cite: 107]. [cite_start]클라이언트는 직렬화, 압축, 요청 라우팅, 오류 처리 및 요청 일괄 처리를 수행합니다[cite: 108].
    * [cite_start]**병렬 요청 및 일괄 처리**: 페이지 요청에 필요한 네트워크 왕복 횟수를 최소화하기 위해 웹 애플리케이션 코드를 구성합니다[cite: 110]. [cite_start]웹 서버는 DAG(Directed Acyclic Graph)를 사용하여 동시에 가져올 수 있는 항목 수를 최대화합니다[cite: 111, 112].
    * [cite_start]**클라이언트-서버 통신**: memcached 서버는 서로 통신하지 않습니다[cite: 114]. [cite_start]시스템의 복잡성은 memcached 서버가 아닌 상태 비저장 클라이언트에 내장되어 있습니다[cite: 115]. [cite_start]클라이언트는 `get` 요청에 UDP를 사용하고 `set` 및 `delete` 작업에 TCP를 사용합니다[cite: 120, 121, 140]. [cite_start]UDP는 지연 시간을 약 20% 줄입니다[cite: 147].
    * [cite_start]**Incast 혼잡**: 클라이언트는 슬라이딩 윈도우 메커니즘을 사용하여 미결 요청 수를 제어하여 incast 혼잡을 제한합니다[cite: 169, 170].
    * [cite_start]**리스(Leases)**: 오래된 세트와 떼 지어 몰려드는 문제를 해결하기 위해 "리스"라는 메커니즘을 도입합니다[cite: 188]. [cite_start]리스는 클라이언트가 캐시에서 데이터를 설정할 수 있도록 memcached 인스턴스가 클라이언트에게 부여하는 64비트 토큰입니다[cite: 194, 195]. [cite_start]리스는 동시 쓰기를 중재하고 오래된 세트를 방지합니다[cite: 197, 199]. [cite_start]또한 떼 지어 몰려드는 문제를 완화하여 데이터베이스 쿼리 속도를 크게 줄입니다[cite: 200, 207, 208].
    * [cite_start]**memcache 풀**: 서로 다른 워크로드를 수용하기 위해 클러스터의 memcached 서버를 별도의 풀로 분할합니다[cite: 230]. [cite_start]이는 다양한 액세스 패턴과 메모리 사용량으로 인한 음의 간섭을 방지합니다[cite: 228, 229, 240].
    * [cite_start]**풀 내 복제**: 높은 요청 속도를 처리하고 지연 시간과 효율성을 향상시키기 위해 특정 풀 내에서 키 범주를 복제합니다[cite: 243, 244, 251, 252].
    * [cite_start]**장애 처리 (Gutter)**: 소수의 호스트가 접근 불가능할 때 백엔드 서비스의 과부하를 방지하기 위해 Gutter라는 전용 머신 세트를 사용합니다[cite: 256, 262]. [cite_start]Gutter는 실패한 서버의 책임을 인계받아 백엔드 스토어의 부하를 줄입니다[cite: 262, 276]. [cite_start]이 시스템은 클라이언트가 볼 수 있는 장애율을 99% 줄입니다[cite: 277].

* **지역 내의 확장 (복제)**:
    * [cite_start]웹 및 memcached 서버를 여러 프런트엔드 클러스터로 분할합니다[cite: 285]. [cite_start]클러스터와 데이터베이스가 포함된 스토리지 클러스터가 함께 지역을 구성합니다[cite: 286].
    * [cite_start]**지역 무효화**: 스토리지 클러스터는 캐시된 데이터를 무효화하여 프런트엔드 클러스터를 권한 있는 버전과 일치시킵니다[cite: 293]. [cite_start]`mcsqueal`이라는 무효화 데몬은 데이터베이스에서 삭제를 추출하고 이를 모든 프런트엔드 클러스터에 브로드캐스트합니다[cite: 307, 308]. [cite_start]삭제는 mcrouter 인스턴스를 실행하는 전용 서버로 일괄 처리되어 패킷 속도를 줄입니다[cite: 313, 315].
    * [cite_start]**지역 풀**: 여러 프런트엔드 클러스터가 동일한 memcached 서버 세트를 공유하는 지역 풀을 사용하여 복제본 수를 줄일 수 있습니다[cite: 330, 331]. [cite_start]이는 대규모이고 거의 액세스되지 않는 항목에 특히 메모리 효율적입니다[cite: 329, 334].
    * [cite_start]**콜드 클러스터 웜업**: 새로운 클러스터를 온라인 상태로 전환하거나 장애 또는 유지보수 시 캐시가 제대로 작동하지 않는 문제를 해결하기 위해 "콜드 클러스터"의 클라이언트가 영구 스토리지 대신 "웜 클러스터"에서 데이터를 검색할 수 있도록 하는 시스템을 사용합니다[cite: 344, 345].

* **지역 간의 확장 (일관성)**:
    * [cite_start]데이터 센터의 지리적 배치는 지연 시간 감소, 자연 재해 완화 및 경제적 인센티브와 같은 이점을 제공합니다[cite: 357, 358, 359, 360].
    * [cite_start]마스터 데이터베이스를 보유하는 마스터 지역과 읽기 전용 복제본을 포함하는 다른 지역으로 구성됩니다[cite: 362].
    * [cite_start]주요 기술적 과제는 memcache의 데이터와 영구 스토리지 간의 일관성을 유지하는 것입니다[cite: 368]. [cite_start]복제 데이터베이스는 마스터 데이터베이스보다 뒤처질 수 있습니다[cite: 369].
    * [cite_start]**원격 마커 메커니즘**: 원격 마커 메커니즘을 사용하여 오래된 데이터를 읽을 가능성을 최소화합니다[cite: 389]. [cite_start]마커가 있으면 로컬 복제 데이터베이스의 데이터가 잠재적으로 오래되었고 쿼리를 마스터 지역으로 리디렉션해야 함을 나타냅니다[cite: 390]. [cite_start]이는 캐시 누락 시 추가 지연 시간을 감수하고 오래된 데이터를 읽을 가능성을 줄이는 것입니다[cite: 392].

* **단일 서버 개선 사항**:
    * [cite_start]**성능 최적화**: 자동 해시 테이블 확장, 다중 스레드 지원(세분화된 잠금 사용), 각 스레드에 자체 UDP 포트를 부여하는 등의 최적화를 통해 memcached의 성능이 크게 향상되었습니다[cite: 415, 423, 427, 428].
    * [cite_start]**적응형 슬랩 할당자**: 현재 워크로드와 일치하도록 슬랩 할당을 주기적으로 재조정하는 적응형 할당자를 구현했습니다[cite: 462].
    * [cite_start]**일시적 항목 캐시**: 짧은 만료 시간을 가진 항목에 대해 사전에 만료된 항목을 제거하는 하이브리드 체계를 도입하여 메모리 낭비를 줄입니다[cite: 471, 472, 475].
    * [cite_start]**소프트웨어 업그레이드**: memcached가 시스템 V 공유 메모리 영역에 캐시된 값과 주요 데이터 구조를 저장하도록 수정하여 소프트웨어 업그레이드 시 데이터가 유지되고 중단을 최소화합니다[cite: 480].

* **memcache 워크로드 특성**:
    * [cite_start]**팬아웃**: 웹 서버가 페이지 요청에 응답할 때 56%의 요청이 20개 미만의 memcached 서버에 접속하지만, 인기 있는 페이지는 100개 이상의 개별 서버에 접속하는 경우가 많습니다[cite: 499, 501, 502].
    * [cite_start]**응답 크기**: 중앙값 응답 크기는 135바이트이고 평균은 954바이트로, 캐시된 항목 크기에 매우 큰 차이가 있음을 나타냅니다[cite: 504].
    * [cite_start]**지연 시간**: 요청 지연 시간 중앙값은 $333\mu s$ 이고, 95번째 백분위수는 $1.135ms$ 입니다[cite: 508].
    * [cite_start]**풀 통계**: 다양한 memcache 풀은 매우 다른 `get`, `set`, `delete` 속도를 보입니다[cite: 536]. [cite_start]복제된 풀은 가장 높은 `get` 속도와 가장 작은 항목 크기에도 불구하고 가장 높은 바이트-패킷 비율을 보입니다[cite: 540].
    * [cite_start]**무효화 지연 시간**: 마스터 지역 내에서 삭제의 소스와 대상이 같은 경우 1초 이내에 99.99%의 신뢰도를 달성합니다[cite: 554]. [cite_start]복제 지역에서 삭제가 발생하고 다른 복제 지역으로 향하는 경우 10분 이내에 99.9%의 신뢰도로 떨어집니다[cite: 555].

* **결론**:
    * [cite_start]캐시 및 영구 스토리지 시스템을 분리하면 독립적으로 확장할 수 있습니다[cite: 594].
    * [cite_start]모니터링, 디버깅 및 운영 효율성을 개선하는 기능은 성능만큼 중요합니다[cite: 595].
    * 상태 저장 구성 요소를 관리하는 것은 상태 비저장 구성 요소보다 운영상 더 복잡합니다. [cite_start]따라서 상태 비저장 클라이언트에 논리를 유지하면 기능 반복을 돕고 중단을 최소화합니다[cite: 596, 597].
    * [cite_start]시스템은 새로운 기능의 점진적인 롤아웃 및 롤백을 지원해야 합니다[cite: 598].
    * [cite_start]단순성은 매우 중요합니다[cite: 599].